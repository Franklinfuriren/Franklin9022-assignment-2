{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82fd7cf-537f-4578-8843-df1688401f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练图像形状: (50000, 32, 32, 3)\n",
      "训练标签形状: (50000,)\n",
      "测试图像形状: (10000, 32, 32, 3)\n",
      "测试标签形状: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def load_cifar10_batch(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='latin1')\n",
    "    return batch\n",
    "\n",
    "def preprocess_cifar10_data(data):\n",
    "    images = data['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  \n",
    "    labels = np.array(data['labels'])\n",
    "    images = images.astype('float32') / 255.0\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_and_preprocess_cifar10(data_dir):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        batch_file = f'{data_dir}/data_batch_{i}'\n",
    "        batch = load_cifar10_batch(batch_file)\n",
    "        images, labels = preprocess_cifar10_data(batch)\n",
    "        train_images.append(images)\n",
    "        train_labels.append(labels)\n",
    "    \n",
    "    train_images = np.concatenate(train_images, axis=0)\n",
    "    train_labels = np.concatenate(train_labels, axis=0)\n",
    "    test_batch = load_cifar10_batch(f'{data_dir}/test_batch')\n",
    "    test_images, test_labels = preprocess_cifar10_data(test_batch)\n",
    "    return (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "data_dir = 'cifar-10'\n",
    "(train_images, train_labels), (test_images, test_labels) = load_and_preprocess_cifar10(data_dir)\n",
    "\n",
    "print(\"训练图像形状:\", train_images.shape)\n",
    "print(\"训练标签形状:\", train_labels.shape)\n",
    "print(\"测试图像形状:\", test_images.shape)\n",
    "print(\"测试标签形状:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adde4ebe-fc17-4a2e-be9a-9981562c7ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,248</span> (364.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,248\u001b[0m (364.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,248</span> (364.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,248\u001b[0m (364.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_encoder(input_shape=(32, 32, 3)):\n",
    "    encoder = models.Sequential(name=\"Encoder\")\n",
    "    encoder.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    encoder.add(layers.MaxPooling2D((2, 2), strides=2))  \n",
    "    encoder.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    encoder.add(layers.MaxPooling2D((2, 2), strides=2)) \n",
    "    encoder.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    encoder.add(layers.MaxPooling2D((2, 2), strides=2))  \n",
    "    return encoder\n",
    "\n",
    "encoder = build_encoder()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9ddfe3-1445-4e21-bd10-44d30f467f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv_transpose.py:94: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">867</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │           \u001b[38;5;34m867\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,707</span> (940.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,707\u001b[0m (940.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,707</span> (940.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m240,707\u001b[0m (940.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">527,114</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m527,114\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">527,114</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m527,114\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_decoder(latent_shape=(4, 4, 128)):\n",
    "    decoder = models.Sequential(name=\"Decoder\")\n",
    "    decoder.add(layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu', input_shape=latent_shape))  \n",
    "    decoder.add(layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu'))  \n",
    "    decoder.add(layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')) \n",
    "    decoder.add(layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid')) \n",
    "    return decoder\n",
    "\n",
    "def build_classifier(latent_shape=(4, 4, 128), num_classes=10):\n",
    "    classifier = models.Sequential(name=\"Classifier\")\n",
    "    classifier.add(layers.Flatten(input_shape=latent_shape))  \n",
    "    classifier.add(layers.Dense(256, activation='relu'))  \n",
    "    classifier.add(layers.Dropout(0.5))  \n",
    "    classifier.add(layers.Dense(num_classes, activation='softmax'))  \n",
    "    return classifier\n",
    "decoder = build_decoder()\n",
    "classifier = build_classifier()\n",
    "print(\"Decoder Summary:\")\n",
    "decoder.summary()\n",
    "\n",
    "print(\"\\nClassifier Summary:\")\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea4a2e0-3e48-4493-8af3-4d90715d919b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Full_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Full_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">93,248</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">240,707</span> │ Encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Classifier          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">527,114</span> │ Encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m93,248\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │    \u001b[38;5;34m240,707\u001b[0m │ Encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Classifier          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m527,114\u001b[0m │ Encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">861,069</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m861,069\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">861,069</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m861,069\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Batch 100/781 - Total Loss: 1.8556, Reconstruction Loss: 0.0325, Classification Loss: 1.8230\n",
      "Batch 200/781 - Total Loss: 1.3355, Reconstruction Loss: 0.0214, Classification Loss: 1.3142\n",
      "Batch 300/781 - Total Loss: 1.3421, Reconstruction Loss: 0.0205, Classification Loss: 1.3216\n",
      "Batch 400/781 - Total Loss: 1.2402, Reconstruction Loss: 0.0181, Classification Loss: 1.2221\n",
      "Batch 500/781 - Total Loss: 1.3494, Reconstruction Loss: 0.0190, Classification Loss: 1.3304\n",
      "Batch 600/781 - Total Loss: 1.0633, Reconstruction Loss: 0.0170, Classification Loss: 1.0463\n",
      "Batch 700/781 - Total Loss: 1.2738, Reconstruction Loss: 0.0146, Classification Loss: 1.2592\n",
      "Epoch 1 - Avg Total Loss: 1.4325, Avg Reconstruction Loss: 0.0228, Avg Classification Loss: 1.4097\n",
      "--------------------------------------------------\n",
      "Epoch 2/10\n",
      "Batch 100/781 - Total Loss: 0.8980, Reconstruction Loss: 0.0188, Classification Loss: 0.8792\n",
      "Batch 200/781 - Total Loss: 0.9202, Reconstruction Loss: 0.0142, Classification Loss: 0.9059\n",
      "Batch 300/781 - Total Loss: 1.0403, Reconstruction Loss: 0.0144, Classification Loss: 1.0259\n",
      "Batch 400/781 - Total Loss: 0.7691, Reconstruction Loss: 0.0155, Classification Loss: 0.7535\n",
      "Batch 500/781 - Total Loss: 0.9007, Reconstruction Loss: 0.0151, Classification Loss: 0.8856\n",
      "Batch 600/781 - Total Loss: 0.9877, Reconstruction Loss: 0.0157, Classification Loss: 0.9720\n",
      "Batch 700/781 - Total Loss: 0.7711, Reconstruction Loss: 0.0157, Classification Loss: 0.7554\n",
      "Epoch 2 - Avg Total Loss: 1.0000, Avg Reconstruction Loss: 0.0154, Avg Classification Loss: 0.9846\n",
      "--------------------------------------------------\n",
      "Epoch 3/10\n",
      "Batch 100/781 - Total Loss: 0.8993, Reconstruction Loss: 0.0133, Classification Loss: 0.8860\n",
      "Batch 200/781 - Total Loss: 1.0771, Reconstruction Loss: 0.0137, Classification Loss: 1.0633\n",
      "Batch 300/781 - Total Loss: 0.7668, Reconstruction Loss: 0.0129, Classification Loss: 0.7539\n",
      "Batch 400/781 - Total Loss: 0.8090, Reconstruction Loss: 0.0136, Classification Loss: 0.7954\n",
      "Batch 500/781 - Total Loss: 0.8590, Reconstruction Loss: 0.0136, Classification Loss: 0.8454\n",
      "Batch 600/781 - Total Loss: 0.7950, Reconstruction Loss: 0.0134, Classification Loss: 0.7816\n",
      "Batch 700/781 - Total Loss: 0.5805, Reconstruction Loss: 0.0154, Classification Loss: 0.5651\n",
      "Epoch 3 - Avg Total Loss: 0.8222, Avg Reconstruction Loss: 0.0139, Avg Classification Loss: 0.8083\n",
      "--------------------------------------------------\n",
      "Epoch 4/10\n",
      "Batch 100/781 - Total Loss: 0.9047, Reconstruction Loss: 0.0123, Classification Loss: 0.8924\n",
      "Batch 200/781 - Total Loss: 0.6512, Reconstruction Loss: 0.0126, Classification Loss: 0.6386\n",
      "Batch 300/781 - Total Loss: 0.5731, Reconstruction Loss: 0.0118, Classification Loss: 0.5613\n",
      "Batch 400/781 - Total Loss: 0.6106, Reconstruction Loss: 0.0190, Classification Loss: 0.5916\n",
      "Batch 500/781 - Total Loss: 0.8842, Reconstruction Loss: 0.0118, Classification Loss: 0.8724\n",
      "Batch 600/781 - Total Loss: 0.5829, Reconstruction Loss: 0.0138, Classification Loss: 0.5691\n",
      "Batch 700/781 - Total Loss: 0.5339, Reconstruction Loss: 0.0134, Classification Loss: 0.5206\n",
      "Epoch 4 - Avg Total Loss: 0.7066, Avg Reconstruction Loss: 0.0135, Avg Classification Loss: 0.6931\n",
      "--------------------------------------------------\n",
      "Epoch 5/10\n",
      "Batch 100/781 - Total Loss: 0.3327, Reconstruction Loss: 0.0120, Classification Loss: 0.3208\n",
      "Batch 200/781 - Total Loss: 0.5748, Reconstruction Loss: 0.0115, Classification Loss: 0.5633\n",
      "Batch 300/781 - Total Loss: 0.5659, Reconstruction Loss: 0.0129, Classification Loss: 0.5530\n",
      "Batch 400/781 - Total Loss: 0.5744, Reconstruction Loss: 0.0144, Classification Loss: 0.5600\n",
      "Batch 500/781 - Total Loss: 0.4893, Reconstruction Loss: 0.0134, Classification Loss: 0.4759\n",
      "Batch 600/781 - Total Loss: 0.6466, Reconstruction Loss: 0.0134, Classification Loss: 0.6332\n",
      "Batch 700/781 - Total Loss: 0.5618, Reconstruction Loss: 0.0116, Classification Loss: 0.5503\n",
      "Epoch 5 - Avg Total Loss: 0.6141, Avg Reconstruction Loss: 0.0130, Avg Classification Loss: 0.6011\n",
      "--------------------------------------------------\n",
      "Epoch 6/10\n",
      "Batch 100/781 - Total Loss: 0.4711, Reconstruction Loss: 0.0117, Classification Loss: 0.4595\n",
      "Batch 200/781 - Total Loss: 0.4990, Reconstruction Loss: 0.0172, Classification Loss: 0.4818\n",
      "Batch 300/781 - Total Loss: 0.6538, Reconstruction Loss: 0.0120, Classification Loss: 0.6418\n",
      "Batch 400/781 - Total Loss: 0.4837, Reconstruction Loss: 0.0123, Classification Loss: 0.4714\n",
      "Batch 500/781 - Total Loss: 0.4167, Reconstruction Loss: 0.0138, Classification Loss: 0.4029\n",
      "Batch 600/781 - Total Loss: 0.5825, Reconstruction Loss: 0.0126, Classification Loss: 0.5700\n",
      "Batch 700/781 - Total Loss: 0.4914, Reconstruction Loss: 0.0140, Classification Loss: 0.4774\n",
      "Epoch 6 - Avg Total Loss: 0.5247, Avg Reconstruction Loss: 0.0127, Avg Classification Loss: 0.5119\n",
      "--------------------------------------------------\n",
      "Epoch 7/10\n",
      "Batch 100/781 - Total Loss: 0.3480, Reconstruction Loss: 0.0123, Classification Loss: 0.3357\n",
      "Batch 200/781 - Total Loss: 0.5272, Reconstruction Loss: 0.0110, Classification Loss: 0.5162\n",
      "Batch 300/781 - Total Loss: 0.3949, Reconstruction Loss: 0.0115, Classification Loss: 0.3834\n",
      "Batch 400/781 - Total Loss: 0.4369, Reconstruction Loss: 0.0115, Classification Loss: 0.4255\n",
      "Batch 500/781 - Total Loss: 0.3642, Reconstruction Loss: 0.0121, Classification Loss: 0.3521\n",
      "Batch 600/781 - Total Loss: 0.3173, Reconstruction Loss: 0.0111, Classification Loss: 0.3062\n",
      "Batch 700/781 - Total Loss: 0.4541, Reconstruction Loss: 0.0120, Classification Loss: 0.4421\n",
      "Epoch 7 - Avg Total Loss: 0.4466, Avg Reconstruction Loss: 0.0124, Avg Classification Loss: 0.4342\n",
      "--------------------------------------------------\n",
      "Epoch 8/10\n",
      "Batch 100/781 - Total Loss: 0.3279, Reconstruction Loss: 0.0140, Classification Loss: 0.3139\n",
      "Batch 200/781 - Total Loss: 0.3883, Reconstruction Loss: 0.0130, Classification Loss: 0.3753\n",
      "Batch 300/781 - Total Loss: 0.5926, Reconstruction Loss: 0.0106, Classification Loss: 0.5820\n",
      "Batch 400/781 - Total Loss: 0.3921, Reconstruction Loss: 0.0120, Classification Loss: 0.3801\n",
      "Batch 500/781 - Total Loss: 0.2027, Reconstruction Loss: 0.0126, Classification Loss: 0.1901\n",
      "Batch 600/781 - Total Loss: 0.3261, Reconstruction Loss: 0.0123, Classification Loss: 0.3137\n",
      "Batch 700/781 - Total Loss: 0.3601, Reconstruction Loss: 0.0154, Classification Loss: 0.3447\n",
      "Epoch 8 - Avg Total Loss: 0.3787, Avg Reconstruction Loss: 0.0125, Avg Classification Loss: 0.3662\n",
      "--------------------------------------------------\n",
      "Epoch 9/10\n",
      "Batch 100/781 - Total Loss: 0.2315, Reconstruction Loss: 0.0111, Classification Loss: 0.2204\n",
      "Batch 200/781 - Total Loss: 0.2627, Reconstruction Loss: 0.0107, Classification Loss: 0.2520\n",
      "Batch 300/781 - Total Loss: 0.2818, Reconstruction Loss: 0.0117, Classification Loss: 0.2702\n",
      "Batch 400/781 - Total Loss: 0.1843, Reconstruction Loss: 0.0114, Classification Loss: 0.1729\n",
      "Batch 500/781 - Total Loss: 0.3906, Reconstruction Loss: 0.0106, Classification Loss: 0.3799\n",
      "Batch 600/781 - Total Loss: 0.3474, Reconstruction Loss: 0.0122, Classification Loss: 0.3351\n",
      "Batch 700/781 - Total Loss: 0.1820, Reconstruction Loss: 0.0121, Classification Loss: 0.1698\n",
      "Epoch 9 - Avg Total Loss: 0.3092, Avg Reconstruction Loss: 0.0120, Avg Classification Loss: 0.2973\n",
      "--------------------------------------------------\n",
      "Epoch 10/10\n",
      "Batch 100/781 - Total Loss: 0.1870, Reconstruction Loss: 0.0107, Classification Loss: 0.1763\n",
      "Batch 200/781 - Total Loss: 0.2489, Reconstruction Loss: 0.0108, Classification Loss: 0.2381\n",
      "Batch 300/781 - Total Loss: 0.1014, Reconstruction Loss: 0.0127, Classification Loss: 0.0887\n",
      "Batch 400/781 - Total Loss: 0.1683, Reconstruction Loss: 0.0132, Classification Loss: 0.1551\n",
      "Batch 500/781 - Total Loss: 0.3269, Reconstruction Loss: 0.0125, Classification Loss: 0.3144\n",
      "Batch 600/781 - Total Loss: 0.1986, Reconstruction Loss: 0.0125, Classification Loss: 0.1861\n",
      "Batch 700/781 - Total Loss: 0.7585, Reconstruction Loss: 0.0129, Classification Loss: 0.7456\n",
      "Epoch 10 - Avg Total Loss: 0.2512, Avg Reconstruction Loss: 0.0121, Avg Classification Loss: 0.2392\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "alpha = 1.0  \n",
    "beta = 1.0   \n",
    "\n",
    "def build_full_model(encoder, decoder, classifier):\n",
    "    input_image = layers.Input(shape=(32, 32, 3), name=\"input_image\")\n",
    "\n",
    "    latent_features = encoder(input_image)\n",
    "\n",
    "    reconstructed_image = decoder(latent_features)\n",
    "\n",
    "    class_probabilities = classifier(latent_features)\n",
    "\n",
    "    full_model = models.Model(inputs=input_image, outputs=[reconstructed_image, class_probabilities], name=\"Full_Model\")\n",
    "    return full_model\n",
    "\n",
    "full_model = build_full_model(encoder, decoder, classifier)\n",
    "full_model.summary()\n",
    "\n",
    "reconstruction_loss_fn = losses.MeanSquaredError()  \n",
    "classification_loss_fn = losses.SparseCategoricalCrossentropy()  \n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "full_model.compile(optimizer=optimizer,\n",
    "                   loss={'Decoder': reconstruction_loss_fn, 'Classifier': classification_loss_fn},\n",
    "                   loss_weights={'Decoder': alpha, 'Classifier': beta})\n",
    "def train_step(model, x_batch, y_batch, alpha, beta):\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstructed_images, class_probabilities = model(x_batch)\n",
    "\n",
    "        reconstruction_loss = reconstruction_loss_fn(x_batch, reconstructed_images)\n",
    "\n",
    "        classification_loss = classification_loss_fn(y_batch, class_probabilities)\n",
    "\n",
    "        total_loss = alpha * reconstruction_loss + beta * classification_loss\n",
    "\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return total_loss, reconstruction_loss, classification_loss\n",
    "\n",
    "def train_model(model, train_images, train_labels, epochs=10, batch_size=64):\n",
    "    num_samples = train_images.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_total_loss = 0.0\n",
    "        epoch_reconstruction_loss = 0.0\n",
    "        epoch_classification_loss = 0.0\n",
    "        \n",
    "        indices = tf.random.shuffle(tf.range(num_samples))\n",
    "        train_images = tf.gather(train_images, indices)\n",
    "        train_labels = tf.gather(train_labels, indices)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            x_batch = train_images[start_idx:end_idx]\n",
    "            y_batch = train_labels[start_idx:end_idx]\n",
    "            total_loss, reconstruction_loss, classification_loss = train_step(model, x_batch, y_batch, alpha, beta)\n",
    "\n",
    "            epoch_total_loss += total_loss\n",
    "            epoch_reconstruction_loss += reconstruction_loss\n",
    "            epoch_classification_loss += classification_loss\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"Batch {batch_idx + 1}/{num_batches} - \"\n",
    "                      f\"Total Loss: {total_loss:.4f}, \"\n",
    "                      f\"Reconstruction Loss: {reconstruction_loss:.4f}, \"\n",
    "                      f\"Classification Loss: {classification_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} - \"\n",
    "              f\"Avg Total Loss: {epoch_total_loss / num_batches:.4f}, \"\n",
    "              f\"Avg Reconstruction Loss: {epoch_reconstruction_loss / num_batches:.4f}, \"\n",
    "              f\"Avg Classification Loss: {epoch_classification_loss / num_batches:.4f}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "train_model(full_model, train_images, train_labels, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ad6001-cf10-4849-b903-47611f4bfebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Batch 100/781 - Total Loss: 0.1199, Reconstruction Loss: 0.0107, Classification Loss: 0.1093\n",
      "Batch 200/781 - Total Loss: 0.2053, Reconstruction Loss: 0.0105, Classification Loss: 0.1949\n",
      "Batch 300/781 - Total Loss: 0.2133, Reconstruction Loss: 0.0115, Classification Loss: 0.2018\n",
      "Batch 400/781 - Total Loss: 0.1784, Reconstruction Loss: 0.0109, Classification Loss: 0.1675\n",
      "Batch 500/781 - Total Loss: 0.2704, Reconstruction Loss: 0.0122, Classification Loss: 0.2583\n",
      "Batch 600/781 - Total Loss: 0.3599, Reconstruction Loss: 0.0114, Classification Loss: 0.3486\n",
      "Batch 700/781 - Total Loss: 0.1128, Reconstruction Loss: 0.0118, Classification Loss: 0.1010\n",
      "Epoch 1 - Avg Total Loss: 0.2109, Avg Reconstruction Loss: 0.0118, Avg Classification Loss: 0.1990\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0120, Classification Accuracy: 74.01%\n",
      "--------------------------------------------------\n",
      "Epoch 2/10\n",
      "Batch 100/781 - Total Loss: 0.1272, Reconstruction Loss: 0.0109, Classification Loss: 0.1164\n",
      "Batch 200/781 - Total Loss: 0.1564, Reconstruction Loss: 0.0108, Classification Loss: 0.1456\n",
      "Batch 300/781 - Total Loss: 0.2098, Reconstruction Loss: 0.0112, Classification Loss: 0.1986\n",
      "Batch 400/781 - Total Loss: 0.2400, Reconstruction Loss: 0.0122, Classification Loss: 0.2278\n",
      "Batch 500/781 - Total Loss: 0.1599, Reconstruction Loss: 0.0122, Classification Loss: 0.1477\n",
      "Batch 600/781 - Total Loss: 0.1461, Reconstruction Loss: 0.0107, Classification Loss: 0.1353\n",
      "Batch 700/781 - Total Loss: 0.2183, Reconstruction Loss: 0.0125, Classification Loss: 0.2058\n",
      "Epoch 2 - Avg Total Loss: 0.1621, Avg Reconstruction Loss: 0.0116, Avg Classification Loss: 0.1505\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0113, Classification Accuracy: 74.35%\n",
      "--------------------------------------------------\n",
      "Epoch 3/10\n",
      "Batch 100/781 - Total Loss: 0.1185, Reconstruction Loss: 0.0098, Classification Loss: 0.1087\n",
      "Batch 200/781 - Total Loss: 0.1066, Reconstruction Loss: 0.0118, Classification Loss: 0.0948\n",
      "Batch 300/781 - Total Loss: 0.2280, Reconstruction Loss: 0.0118, Classification Loss: 0.2162\n",
      "Batch 400/781 - Total Loss: 0.1183, Reconstruction Loss: 0.0114, Classification Loss: 0.1069\n",
      "Batch 500/781 - Total Loss: 0.2344, Reconstruction Loss: 0.0111, Classification Loss: 0.2233\n",
      "Batch 600/781 - Total Loss: 0.1496, Reconstruction Loss: 0.0110, Classification Loss: 0.1386\n",
      "Batch 700/781 - Total Loss: 0.2031, Reconstruction Loss: 0.0128, Classification Loss: 0.1903\n",
      "Epoch 3 - Avg Total Loss: 0.1474, Avg Reconstruction Loss: 0.0116, Avg Classification Loss: 0.1359\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0121, Classification Accuracy: 73.29%\n",
      "--------------------------------------------------\n",
      "Epoch 4/10\n",
      "Batch 100/781 - Total Loss: 0.0414, Reconstruction Loss: 0.0113, Classification Loss: 0.0301\n",
      "Batch 200/781 - Total Loss: 0.0907, Reconstruction Loss: 0.0118, Classification Loss: 0.0789\n",
      "Batch 300/781 - Total Loss: 0.1263, Reconstruction Loss: 0.0122, Classification Loss: 0.1141\n",
      "Batch 400/781 - Total Loss: 0.1314, Reconstruction Loss: 0.0117, Classification Loss: 0.1196\n",
      "Batch 500/781 - Total Loss: 0.2814, Reconstruction Loss: 0.0141, Classification Loss: 0.2673\n",
      "Batch 600/781 - Total Loss: 0.1518, Reconstruction Loss: 0.0119, Classification Loss: 0.1399\n",
      "Batch 700/781 - Total Loss: 0.0963, Reconstruction Loss: 0.0119, Classification Loss: 0.0843\n",
      "Epoch 4 - Avg Total Loss: 0.1241, Avg Reconstruction Loss: 0.0114, Avg Classification Loss: 0.1127\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0120, Classification Accuracy: 75.03%\n",
      "--------------------------------------------------\n",
      "Epoch 5/10\n",
      "Batch 100/781 - Total Loss: 0.0685, Reconstruction Loss: 0.0104, Classification Loss: 0.0581\n",
      "Batch 200/781 - Total Loss: 0.1163, Reconstruction Loss: 0.0110, Classification Loss: 0.1053\n",
      "Batch 300/781 - Total Loss: 0.1047, Reconstruction Loss: 0.0105, Classification Loss: 0.0942\n",
      "Batch 400/781 - Total Loss: 0.1247, Reconstruction Loss: 0.0113, Classification Loss: 0.1135\n",
      "Batch 500/781 - Total Loss: 0.0454, Reconstruction Loss: 0.0113, Classification Loss: 0.0341\n",
      "Batch 600/781 - Total Loss: 0.0950, Reconstruction Loss: 0.0120, Classification Loss: 0.0830\n",
      "Batch 700/781 - Total Loss: 0.1337, Reconstruction Loss: 0.0111, Classification Loss: 0.1226\n",
      "Epoch 5 - Avg Total Loss: 0.1177, Avg Reconstruction Loss: 0.0115, Avg Classification Loss: 0.1062\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0119, Classification Accuracy: 74.04%\n",
      "--------------------------------------------------\n",
      "Epoch 6/10\n",
      "Batch 100/781 - Total Loss: 0.1093, Reconstruction Loss: 0.0109, Classification Loss: 0.0985\n",
      "Batch 200/781 - Total Loss: 0.0377, Reconstruction Loss: 0.0112, Classification Loss: 0.0264\n",
      "Batch 300/781 - Total Loss: 0.0787, Reconstruction Loss: 0.0120, Classification Loss: 0.0668\n",
      "Batch 400/781 - Total Loss: 0.0659, Reconstruction Loss: 0.0117, Classification Loss: 0.0541\n",
      "Batch 500/781 - Total Loss: 0.1082, Reconstruction Loss: 0.0112, Classification Loss: 0.0970\n",
      "Batch 600/781 - Total Loss: 0.1491, Reconstruction Loss: 0.0124, Classification Loss: 0.1367\n",
      "Batch 700/781 - Total Loss: 0.1122, Reconstruction Loss: 0.0111, Classification Loss: 0.1010\n",
      "Epoch 6 - Avg Total Loss: 0.1059, Avg Reconstruction Loss: 0.0114, Avg Classification Loss: 0.0945\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0115, Classification Accuracy: 73.38%\n",
      "--------------------------------------------------\n",
      "Epoch 7/10\n",
      "Batch 100/781 - Total Loss: 0.0458, Reconstruction Loss: 0.0119, Classification Loss: 0.0339\n",
      "Batch 200/781 - Total Loss: 0.1040, Reconstruction Loss: 0.0113, Classification Loss: 0.0927\n",
      "Batch 300/781 - Total Loss: 0.1787, Reconstruction Loss: 0.0110, Classification Loss: 0.1678\n",
      "Batch 400/781 - Total Loss: 0.0690, Reconstruction Loss: 0.0112, Classification Loss: 0.0578\n",
      "Batch 500/781 - Total Loss: 0.1419, Reconstruction Loss: 0.0110, Classification Loss: 0.1309\n",
      "Batch 600/781 - Total Loss: 0.0513, Reconstruction Loss: 0.0110, Classification Loss: 0.0404\n",
      "Batch 700/781 - Total Loss: 0.1247, Reconstruction Loss: 0.0108, Classification Loss: 0.1139\n",
      "Epoch 7 - Avg Total Loss: 0.1040, Avg Reconstruction Loss: 0.0115, Avg Classification Loss: 0.0926\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0121, Classification Accuracy: 74.77%\n",
      "--------------------------------------------------\n",
      "Epoch 8/10\n",
      "Batch 100/781 - Total Loss: 0.1011, Reconstruction Loss: 0.0111, Classification Loss: 0.0900\n",
      "Batch 200/781 - Total Loss: 0.0849, Reconstruction Loss: 0.0120, Classification Loss: 0.0729\n",
      "Batch 300/781 - Total Loss: 0.0883, Reconstruction Loss: 0.0097, Classification Loss: 0.0787\n",
      "Batch 400/781 - Total Loss: 0.0693, Reconstruction Loss: 0.0127, Classification Loss: 0.0565\n",
      "Batch 500/781 - Total Loss: 0.0693, Reconstruction Loss: 0.0119, Classification Loss: 0.0574\n",
      "Batch 600/781 - Total Loss: 0.0450, Reconstruction Loss: 0.0112, Classification Loss: 0.0338\n",
      "Batch 700/781 - Total Loss: 0.0388, Reconstruction Loss: 0.0122, Classification Loss: 0.0266\n",
      "Epoch 8 - Avg Total Loss: 0.0886, Avg Reconstruction Loss: 0.0113, Avg Classification Loss: 0.0773\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0115, Classification Accuracy: 75.12%\n",
      "--------------------------------------------------\n",
      "Epoch 9/10\n",
      "Batch 100/781 - Total Loss: 0.0688, Reconstruction Loss: 0.0110, Classification Loss: 0.0578\n",
      "Batch 200/781 - Total Loss: 0.0789, Reconstruction Loss: 0.0114, Classification Loss: 0.0675\n",
      "Batch 300/781 - Total Loss: 0.1362, Reconstruction Loss: 0.0132, Classification Loss: 0.1230\n",
      "Batch 400/781 - Total Loss: 0.0459, Reconstruction Loss: 0.0138, Classification Loss: 0.0321\n",
      "Batch 500/781 - Total Loss: 0.1338, Reconstruction Loss: 0.0119, Classification Loss: 0.1219\n",
      "Batch 600/781 - Total Loss: 0.0298, Reconstruction Loss: 0.0114, Classification Loss: 0.0184\n",
      "Batch 700/781 - Total Loss: 0.1121, Reconstruction Loss: 0.0128, Classification Loss: 0.0992\n",
      "Epoch 9 - Avg Total Loss: 0.0978, Avg Reconstruction Loss: 0.0116, Avg Classification Loss: 0.0862\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0122, Classification Accuracy: 74.18%\n",
      "--------------------------------------------------\n",
      "Epoch 10/10\n",
      "Batch 100/781 - Total Loss: 0.0573, Reconstruction Loss: 0.0113, Classification Loss: 0.0460\n",
      "Batch 200/781 - Total Loss: 0.0813, Reconstruction Loss: 0.0126, Classification Loss: 0.0686\n",
      "Batch 300/781 - Total Loss: 0.0174, Reconstruction Loss: 0.0101, Classification Loss: 0.0072\n",
      "Batch 400/781 - Total Loss: 0.0449, Reconstruction Loss: 0.0114, Classification Loss: 0.0335\n",
      "Batch 500/781 - Total Loss: 0.0805, Reconstruction Loss: 0.0109, Classification Loss: 0.0696\n",
      "Batch 600/781 - Total Loss: 0.0928, Reconstruction Loss: 0.0115, Classification Loss: 0.0812\n",
      "Batch 700/781 - Total Loss: 0.1506, Reconstruction Loss: 0.0117, Classification Loss: 0.1389\n",
      "Epoch 10 - Avg Total Loss: 0.0783, Avg Reconstruction Loss: 0.0113, Avg Classification Loss: 0.0670\n",
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0114, Classification Accuracy: 74.10%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers, metrics\n",
    "alpha = 1.0  \n",
    "beta = 1.0   \n",
    "\n",
    "def build_full_model(encoder, decoder, classifier):\n",
    "    input_image = layers.Input(shape=(32, 32, 3), name=\"input_image\")\n",
    "    latent_features = encoder(input_image)\n",
    "    reconstructed_image = decoder(latent_features)\n",
    "    class_probabilities = classifier(latent_features)\n",
    "    full_model = models.Model(inputs=input_image, outputs=[reconstructed_image, class_probabilities], name=\"Full_Model\")\n",
    "    return full_model\n",
    "\n",
    "full_model = build_full_model(encoder, decoder, classifier)\n",
    "\n",
    "reconstruction_loss_fn = losses.MeanSquaredError()  \n",
    "classification_loss_fn = losses.SparseCategoricalCrossentropy()  \n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "def train_step(model, x_batch, y_batch, alpha, beta):\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstructed_images, class_probabilities = model(x_batch)\n",
    "\n",
    "        reconstruction_loss = reconstruction_loss_fn(x_batch, reconstructed_images)\n",
    "\n",
    "        classification_loss = classification_loss_fn(y_batch, class_probabilities)\n",
    "\n",
    "        total_loss = alpha * reconstruction_loss + beta * classification_loss\n",
    "\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return total_loss, reconstruction_loss, classification_loss\n",
    "\n",
    "def train_model(model, train_images, train_labels, test_images, test_labels, epochs=10, batch_size=64):\n",
    "    num_samples = train_images.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        epoch_total_loss = 0.0\n",
    "        epoch_reconstruction_loss = 0.0\n",
    "        epoch_classification_loss = 0.0\n",
    "\n",
    "        indices = tf.random.shuffle(tf.range(num_samples))\n",
    "        train_images = tf.gather(train_images, indices)\n",
    "        train_labels = tf.gather(train_labels, indices)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            x_batch = train_images[start_idx:end_idx]\n",
    "            y_batch = train_labels[start_idx:end_idx]\n",
    "            total_loss, reconstruction_loss, classification_loss = train_step(model, x_batch, y_batch, alpha, beta)\n",
    "            epoch_total_loss += total_loss\n",
    "            epoch_reconstruction_loss += reconstruction_loss\n",
    "            epoch_classification_loss += classification_loss\n",
    "\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"Batch {batch_idx + 1}/{num_batches} - \"\n",
    "                      f\"Total Loss: {total_loss:.4f}, \"\n",
    "                      f\"Reconstruction Loss: {reconstruction_loss:.4f}, \"\n",
    "                      f\"Classification Loss: {classification_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch + 1} - \"\n",
    "              f\"Avg Total Loss: {epoch_total_loss / num_batches:.4f}, \"\n",
    "              f\"Avg Reconstruction Loss: {epoch_reconstruction_loss / num_batches:.4f}, \"\n",
    "              f\"Avg Classification Loss: {epoch_classification_loss / num_batches:.4f}\")\n",
    "        evaluate_model(model, test_images, test_labels)\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "def evaluate_model(model, test_images, test_labels):\n",
    "    reconstructed_images, class_probabilities = model(test_images)\n",
    "\n",
    "    reconstruction_loss = reconstruction_loss_fn(test_images, reconstructed_images).numpy()\n",
    "\n",
    "    predicted_labels = tf.argmax(class_probabilities, axis=1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_labels, test_labels), tf.float32)).numpy()\n",
    "\n",
    "    print(f\"Test Set Evaluation - \"\n",
    "          f\"Reconstruction Loss (MSE): {reconstruction_loss:.4f}, \"\n",
    "          f\"Classification Accuracy: {accuracy * 100:.2f}%\")\n",
    "train_model(full_model, train_images, train_labels, test_images, test_labels, epochs=10, batch_size=64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d67f41fc-b383-4752-ae0d-f2400dbb4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation - Reconstruction Loss (MSE): 0.0114, Classification Accuracy: 74.10%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_images, test_labels):\n",
    "    reconstructed_images, class_probabilities = model(test_images)\n",
    "    reconstruction_loss = reconstruction_loss_fn(test_images, reconstructed_images).numpy()\n",
    "    predicted_labels = tf.argmax(class_probabilities, axis=1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_labels, test_labels), tf.float32)).numpy()\n",
    "    print(f\"Test Set Evaluation - \"\n",
    "          f\"Reconstruction Loss (MSE): {reconstruction_loss:.4f}, \"\n",
    "          f\"Classification Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return reconstruction_loss, accuracy\n",
    "test_reconstruction_loss, test_accuracy = evaluate_model(full_model, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b9b89-a774-474b-b287-36c3d2eea5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assign2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
